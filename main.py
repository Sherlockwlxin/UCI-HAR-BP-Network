"""
ä¸»ç¨‹åº - UCI HARæ•°æ®é›†äººä½“è¡Œä¸ºè¯†åˆ«å®éªŒ
åŸºäºæ‰‹å·¥å®ç°çš„BPç¥ç»ç½‘ç»œ

ä½œè€…: [ä½ çš„å§“å]
æ—¥æœŸ: 2026å¹´1æœˆ
è¯¾ç¨‹: æœºå™¨å­¦ä¹ 
"""

import numpy as np
import time
import os
from bp_neural_network import BPNeuralNetwork
from data_preprocessing import prepare_data, get_activity_names
from visualization import (plot_training_history, plot_confusion_matrix, 
                          plot_loss_curve_single, plot_accuracy_curve_single,
                          print_classification_report, analyze_confusion_pairs)


def print_header(text):
    """æ‰“å°ç¾åŒ–çš„æ ‡é¢˜"""
    print("\n" + "=" * 70)
    print(f"  {text}")
    print("=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    print_header("UCI HAR äººä½“è¡Œä¸ºè¯†åˆ«å®éªŒ")
    print("åŸºäºæ”¹è¿›BPç®—æ³•çš„å¤šå±‚æ„ŸçŸ¥æœºå®ç°")
    print("æœ¬å®éªŒå®Œå…¨åŸºäºNumPyæ‰‹å·¥å®ç°ï¼Œä¸ä¾èµ–æ·±åº¦å­¦ä¹ æ¡†æ¶\n")
    
    # ========== 1. è®¾ç½®éšæœºç§å­ ==========
    np.random.seed(42)
    print("âœ“ éšæœºç§å­å·²è®¾ç½®: 42 (ç¡®ä¿å®éªŒå¯å¤ç°)")
    
    # ========== 2. æ•°æ®å‡†å¤‡ ==========
    print_header("æ­¥éª¤ 1: æ•°æ®åŠ è½½ä¸é¢„å¤„ç†")
    
    data_path = 'UCI HAR Dataset'
    
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_path):
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†ç›®å½• '{data_path}'")
        print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤å‡†å¤‡æ•°æ®:")
        print("1. ä¸‹è½½æ•°æ®é›†: https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones")
        print("2. è§£å‹ 'UCI HAR Dataset.zip'")
        print("3. ç¡®ä¿ç›®å½•ç»“æ„å¦‚ä¸‹:")
        print("   Project_Folder/")
        print("   |-- main.py")
        print("   |-- UCI HAR Dataset/")
        print("       |-- train/")
        print("       |-- test/")
        return
    
    try:
        X_train, y_train, X_val, y_val, X_test, y_test = prepare_data(
            data_path=data_path,
            validation_split=0.15
        )
    except FileNotFoundError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return
    
    activity_names = get_activity_names()
    
    # ========== 3. æ¨¡å‹é…ç½® ==========
    print_header("æ­¥éª¤ 2: æ¨¡å‹é…ç½®")
    
    input_size = X_train.shape[1]  # 561
    hidden_size = 64               # éšè—å±‚ç¥ç»å…ƒæ•°
    output_size = 6                # 6ä¸ªç±»åˆ«
    learning_rate = 0.01           # é™ä½å­¦ä¹ ç‡ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸
    epochs = 100
    batch_size = 32
    
    print(f"ç½‘ç»œç»“æ„: {input_size} â†’ {hidden_size} (ReLU) â†’ {output_size} (Softmax)")
    print(f"å­¦ä¹ ç‡: {learning_rate}")
    print(f"è®­ç»ƒè½®æ•°: {epochs}")
    print(f"æ‰¹å¤§å°: {batch_size}")
    
    # ========== 4. å®éªŒç»„1: æ ‡å‡†BPç®—æ³• ==========
    print_header("æ­¥éª¤ 3: è®­ç»ƒæ ‡å‡†BPç¥ç»ç½‘ç»œ (æ— åŠ¨é‡)")
    
    model_standard = BPNeuralNetwork(
        input_size=input_size,
        hidden_size=hidden_size,
        output_size=output_size,
        learning_rate=learning_rate,
        momentum=0.0,  # æ ‡å‡†BP
        activation='relu'
    )
    
    print("å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()
    
    model_standard.fit(
        X_train, y_train,
        X_val, y_val,
        epochs=epochs,
        batch_size=batch_size,
        verbose=True
    )
    
    train_time_standard = time.time() - start_time
    print(f"\nâœ“ æ ‡å‡†BPè®­ç»ƒå®Œæˆ! è€—æ—¶: {train_time_standard:.2f} ç§’")
    
    # è¯„ä¼°æ ‡å‡†BP
    _, test_acc_standard, y_pred_standard = model_standard.evaluate(X_test, y_test)
    print(f"âœ“ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc_standard:.4f} ({test_acc_standard*100:.2f}%)")
    
    # ========== 5. å®éªŒç»„2: Momentum BPç®—æ³• ==========
    print_header("æ­¥éª¤ 4: è®­ç»ƒMomentum BPç¥ç»ç½‘ç»œ (Î±=0.9)")
    
    model_momentum = BPNeuralNetwork(
        input_size=input_size,
        hidden_size=hidden_size,
        output_size=output_size,
        learning_rate=learning_rate,
        momentum=0.9,  # å¼•å…¥åŠ¨é‡
        activation='relu'
    )
    
    print("å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()
    
    model_momentum.fit(
        X_train, y_train,
        X_val, y_val,
        epochs=epochs,
        batch_size=batch_size,
        verbose=True
    )
    
    train_time_momentum = time.time() - start_time
    print(f"\nâœ“ Momentum BPè®­ç»ƒå®Œæˆ! è€—æ—¶: {train_time_momentum:.2f} ç§’")
    
    # è¯„ä¼°Momentum BP
    _, test_acc_momentum, y_pred_momentum = model_momentum.evaluate(X_test, y_test)
    print(f"âœ“ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc_momentum:.4f} ({test_acc_momentum*100:.2f}%)")
    
    # ========== 6. æ€§èƒ½å¯¹æ¯” ==========
    print_header("æ­¥éª¤ 5: å®éªŒç»“æœå¯¹æ¯”")
    
    print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”è¡¨:")
    print("-" * 70)
    print(f"{'æŒ‡æ ‡':<25} {'æ ‡å‡†BP':<20} {'Momentum BP':<20}")
    print("-" * 70)
    print(f"{'è®­ç»ƒæ—¶é—´ (ç§’)':<25} {train_time_standard:<20.2f} {train_time_momentum:<20.2f}")
    print(f"{'æœ€ç»ˆè®­ç»ƒæŸå¤±':<25} {model_standard.train_loss_history[-1]:<20.4f} {model_momentum.train_loss_history[-1]:<20.4f}")
    print(f"{'æœ€ç»ˆéªŒè¯æŸå¤±':<25} {model_standard.val_loss_history[-1]:<20.4f} {model_momentum.val_loss_history[-1]:<20.4f}")
    print(f"{'æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡':<25} {model_standard.train_acc_history[-1]:<20.4f} {model_momentum.train_acc_history[-1]:<20.4f}")
    print(f"{'æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡':<25} {model_standard.val_acc_history[-1]:<20.4f} {model_momentum.val_acc_history[-1]:<20.4f}")
    print(f"{'æµ‹è¯•é›†å‡†ç¡®ç‡':<25} {test_acc_standard:<20.4f} {test_acc_momentum:<20.4f}")
    print("-" * 70)
    
    # æ”¶æ•›é€Ÿåº¦åˆ†æ
    print("\nğŸ“ˆ æ”¶æ•›é€Ÿåº¦åˆ†æ:")
    threshold = 0.5
    epochs_to_converge_std = next((i for i, loss in enumerate(model_standard.train_loss_history) 
                                   if loss < threshold), epochs)
    epochs_to_converge_mom = next((i for i, loss in enumerate(model_momentum.train_loss_history) 
                                   if loss < threshold), epochs)
    
    print(f"è¾¾åˆ°æŸå¤±<{threshold}æ‰€éœ€è½®æ•°:")
    print(f"  - æ ‡å‡†BP: {epochs_to_converge_std} epochs")
    print(f"  - Momentum BP: {epochs_to_converge_mom} epochs")
    if epochs_to_converge_std > 0 and epochs_to_converge_mom < epochs_to_converge_std:
        speedup = (epochs_to_converge_std - epochs_to_converge_mom) / epochs_to_converge_std * 100
        print(f"  - åŠ¨é‡æ³•åŠ é€Ÿ: {speedup:.1f}% æ›´å¿«!")
    elif epochs_to_converge_mom < epochs_to_converge_std:
        print(f"  - åŠ¨é‡æ³•æ›´å¿«æ”¶æ•›")
    else:
        print(f"  - æ ‡å‡†BPæ”¶æ•›æ›´å¿«æˆ–ä¸¤è€…ç›¸è¿‘")
    
    # ========== 7. å¯è§†åŒ– ==========
    print_header("æ­¥éª¤ 6: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = 'results'
    os.makedirs(output_dir, exist_ok=True)
    
    # 7.1 è®­ç»ƒå†å²å¯¹æ¯”
    plot_training_history(
        model_standard, 
        model_momentum,
        save_path=os.path.join(output_dir, 'training_comparison.png')
    )
    
    # 7.2 æ··æ·†çŸ©é˜µ - Momentum BP (æ€§èƒ½æ›´å¥½çš„æ¨¡å‹)
    plot_confusion_matrix(
        y_test, 
        y_pred_momentum,
        activity_names,
        title='Confusion Matrix - Momentum BP',
        save_path=os.path.join(output_dir, 'confusion_matrix_momentum.png')
    )
    
    # 7.3 æ··æ·†çŸ©é˜µ - æ ‡å‡†BP
    plot_confusion_matrix(
        y_test, 
        y_pred_standard,
        activity_names,
        title='Confusion Matrix - Standard BP',
        save_path=os.path.join(output_dir, 'confusion_matrix_standard.png')
    )
    
    # 7.4 å•ç‹¬çš„æŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿ (Momentum BP)
    plot_loss_curve_single(
        model_momentum,
        save_path=os.path.join(output_dir, 'loss_curve_momentum.png')
    )
    
    plot_accuracy_curve_single(
        model_momentum,
        save_path=os.path.join(output_dir, 'accuracy_curve_momentum.png')
    )
    
    # ========== 8. è¯¦ç»†åˆ†ç±»åˆ†æ ==========
    print_header("æ­¥éª¤ 7: Momentum BPæ¨¡å‹è¯¦ç»†åˆ†æ")
    
    print_classification_report(y_test, y_pred_momentum, activity_names)
    
    analyze_confusion_pairs(y_test, y_pred_momentum, activity_names)
    
    # ========== 9. é‡ç‚¹åˆ†æ: Sitting vs Standing ==========
    print("\n" + "=" * 70)
    print("ğŸ” é‡ç‚¹åˆ†æ: 'Sitting' å’Œ 'Standing' çš„æ··æ·†æƒ…å†µ")
    print("=" * 70)
    
    y_true_labels = np.argmax(y_test, axis=1)
    
    # Sitting (ç±»åˆ«3) è¢«è¯¯åˆ¤ä¸º Standing (ç±»åˆ«4) çš„æ¬¡æ•°
    sitting_to_standing = np.sum((y_true_labels == 3) & (y_pred_momentum == 4))
    standing_to_sitting = np.sum((y_true_labels == 4) & (y_pred_momentum == 3))
    
    total_sitting = np.sum(y_true_labels == 3)
    total_standing = np.sum(y_true_labels == 4)
    
    print(f"\nSitting â†’ Standing è¯¯åˆ¤: {sitting_to_standing}/{total_sitting} "
          f"({sitting_to_standing/total_sitting*100:.2f}%)")
    print(f"Standing â†’ Sitting è¯¯åˆ¤: {standing_to_sitting}/{total_standing} "
          f"({standing_to_sitting/total_standing*100:.2f}%)")
    
    print("\nåˆ†æ:")
    print("Sittingå’ŒStandingåœ¨ä¼ æ„Ÿå™¨æ•°æ®ä¸Šéå¸¸ç›¸ä¼¼,å› ä¸º:")
    print("1. ä¸¤ç§çŠ¶æ€éƒ½æ˜¯é™æ­¢çš„,åŠ é€Ÿåº¦å˜åŒ–å°")
    print("2. é‡åŠ›æ–¹å‘ç›¸ä¼¼,é™€èºä»ªè¯»æ•°æ¥è¿‘")
    print("3. åªæœ‰èº«ä½“å§¿æ€çš„ç»†å¾®å·®å¼‚")
    
    # ========== 10. æ€»ç»“ ==========
    print_header("å®éªŒæ€»ç»“")
    
    print("\nâœ… å®éªŒå®Œæˆ! ä¸»è¦å‘ç°:")
    print("\n1. åŠ¨é‡æ³•æ”¹è¿›æ•ˆæœ:")
    if epochs_to_converge_std > 0:
        speedup_pct = ((epochs_to_converge_std - epochs_to_converge_mom) / epochs_to_converge_std * 100)
        print(f"   - æ”¶æ•›é€Ÿåº¦æå‡çº¦ {speedup_pct:.1f}%")
    else:
        print(f"   - æ”¶æ•›é€Ÿåº¦å¯¹æ¯”: æ ‡å‡†BP {epochs_to_converge_std} epochs vs Momentum BP {epochs_to_converge_mom} epochs")
    print(f"   - æµ‹è¯•å‡†ç¡®ç‡: {test_acc_momentum*100:.2f}% (vs æ ‡å‡†BP {test_acc_standard*100:.2f}%)")
    
    print("\n2. æ¨¡å‹æ€§èƒ½:")
    print(f"   - æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc_momentum*100:.2f}%")
    print(f"   - é«˜ç»´ç‰¹å¾ (561ç»´) ä¸‹çš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›")
    
    print("\n3. åˆ†ç±»éš¾ç‚¹:")
    print("   - Sittingå’ŒStandingå®¹æ˜“æ··æ·† (é™æ€å§¿æ€ç›¸ä¼¼)")
    print("   - åŠ¨æ€æ´»åŠ¨ (Walkingç³»åˆ—) è¯†åˆ«å‡†ç¡®ç‡è¾ƒé«˜")
    
    print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° '{output_dir}' ç›®å½•:")
    print(f"   - training_comparison.png: è®­ç»ƒå†å²å¯¹æ¯”å›¾")
    print(f"   - confusion_matrix_momentum.png: Momentum BPæ··æ·†çŸ©é˜µ")
    print(f"   - confusion_matrix_standard.png: æ ‡å‡†BPæ··æ·†çŸ©é˜µ")
    print(f"   - loss_curve_momentum.png: æŸå¤±æ›²çº¿")
    print(f"   - accuracy_curve_momentum.png: å‡†ç¡®ç‡æ›²çº¿")
    
    print("\n" + "=" * 70)
    print("å®éªŒæŠ¥å‘Šå¯ä»¥åŸºäºä»¥ä¸Šç»“æœæ’°å†™!")
    print("=" * 70)


if __name__ == "__main__":
    main()
